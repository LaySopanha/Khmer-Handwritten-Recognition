{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0064b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "os.environ[\"LABEL_STUDIO_MODE\"] = \"http\"\n",
    "os.environ[\"LABEL_STUDIO_ROOT\"] = str(pathlib.Path(\"../data/raw\").resolve())\n",
    "os.environ[\"LABEL_STUDIO_PREFIX\"] = \"http://localhost:8081/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b53fdbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR, TextDetection\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from urllib.parse import quote\n",
    "import os\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e350a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"../data/raw/2025_10_14 18_29 Office Lens.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3574884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/lsp/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32m{'res': {'input_path': '../data/raw/2025_10_14 18_29 Office Lens.jpg', 'page_index': None, 'dt_polys': array([[[ 507, 2967],\n",
      "        ...,\n",
      "        [ 507, 3048]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1967,    0],\n",
      "        ...,\n",
      "        [1967,   85]]], dtype=int16), 'dt_scores': [0.9599240393972852, 0.7992695134289577, 0.6329533001107555, 0.9076279939538324, 0.6344320727857174, 0.8672609783445228, 0.8900721293464173, 0.8647542974751244, 0.7109516768942047, 0.8107423066259318, 0.8285057409200374, 0.8751889975026965, 0.8288574814599294, 0.8922069839498309, 0.8067582327402847, 0.837873264115583, 0.6199746409963284, 0.8481544643165515, 0.7640712800031367, 0.8963516775880304, 0.9001908962534174, 0.7225446159736468, 0.8286460573537537, 0.9118613200759041, 0.7091356070591665, 0.9356038020391273, 0.8896376613725255, 0.8421491763551705, 0.8693845282843901, 0.9051775038116306, 0.8678892733457033, 0.7363039446784324, 0.8304139287876288, 0.7731410965748617, 0.9143610408743067, 0.89844636477492]}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = TextDetection(model_name=\"PP-OCRv5_server_det\")\n",
    "output = model.predict(image, batch_size=1)\n",
    "for res in output:\n",
    "    res.print()\n",
    "    res.save_to_img(save_path=\"./output/\")\n",
    "    res.save_to_json(save_path=\"./output/res.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c893b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d919df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 36 polygons to output/ls_preannotations.json\n"
     ]
    }
   ],
   "source": [
    "from_name = \"lines\"  # PolygonLabels name in Label Studio\n",
    "to_name = \"image\"     # Image tag name\n",
    "label = \"text\"        # Label value\n",
    "model_version = \"paddle-ppocrv5\"\n",
    "label_studio_mode = os.environ.get(\"LABEL_STUDIO_MODE\", \"local-files\")  # local-files, http, or storage\n",
    "label_studio_root = Path(os.environ.get(\"LABEL_STUDIO_ROOT\", Path.cwd().resolve()))\n",
    "label_studio_prefix = os.environ.get(\"LABEL_STUDIO_PREFIX\", \"/data/local-files/?d=\")\n",
    "image_path = Path(image).resolve()\n",
    "\n",
    "def make_image_entry(path: Path) -> str:\n",
    "    if label_studio_mode == \"http\":\n",
    "        prefix = label_studio_prefix.rstrip(\"/\") + \"/\"\n",
    "        rel = path.resolve().relative_to(label_studio_root.resolve())\n",
    "        return f\"{prefix}{quote(rel.as_posix())}\"\n",
    "    rel = path.resolve().relative_to(label_studio_root.resolve())\n",
    "    if label_studio_mode == \"storage\":\n",
    "        return rel.as_posix()\n",
    "    # default local-files handler\n",
    "    if not label_studio_root.exists():\n",
    "        raise FileNotFoundError(f\"label_studio_root {label_studio_root} does not exist\")\n",
    "    return f\"{label_studio_prefix}{quote(rel.as_posix())}\"\n",
    "image_entry = make_image_entry(image_path)\n",
    "\n",
    "img_w, img_h = Image.open(image).size\n",
    "raw = output[0]\n",
    "res_dict = raw[\"res\"] if isinstance(raw, dict) and \"res\" in raw else getattr(raw, \"res\", raw)\n",
    "dt_polys = res_dict[\"dt_polys\"] if isinstance(res_dict, dict) else getattr(res_dict, \"dt_polys\", [])\n",
    "dt_scores = res_dict[\"dt_scores\"] if isinstance(res_dict, dict) else getattr(res_dict, \"dt_scores\", [])\n",
    "polygons = []\n",
    "for poly, score in zip(dt_polys.tolist(), dt_scores):\n",
    "    normalized = [\n",
    "        [round(x / img_w * 100, 4), round(y / img_h * 100, 4)]\n",
    "        for x, y in poly\n",
    "    ]\n",
    "    polygons.append({\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"from_name\": from_name,\n",
    "        \"to_name\": to_name,\n",
    "        \"type\": \"polygonlabels\",\n",
    "        \"score\": float(score),\n",
    "        \"value\": {\n",
    "            \"points\": normalized,\n",
    "            \"polygonlabels\": [label]\n",
    "        }\n",
    "    })\n",
    "\n",
    "payload = [{\n",
    "    \"data\": {\"image\": image_entry},\n",
    "    \"predictions\": [{\n",
    "        \"model_version\": model_version,\n",
    "        \"result\": polygons,\n",
    "        \"score\": float(sum(dt_scores) / len(dt_scores)) if dt_scores else None\n",
    "    }]\n",
    "}]\n",
    "\n",
    "out_path = Path(\"output/ls_preannotations.json\")\n",
    "out_path.parent.mkdir(exist_ok=True)\n",
    "out_path.write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n",
    "print(f\"Wrote {len(polygons)} polygons to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661c9ce",
   "metadata": {},
   "source": [
    "### Importing into Label Studio\n",
    "1. Make sure the labeling config contains `<Image name=\"image\" value=\"$image\"/>` and `<PolygonLabels name=\"lines\" toName=\"image\">` with a `text` label (or change the variables in the conversion cell).\n",
    "2. Optional: set `LABEL_STUDIO_MODE` (`local-files` for `/data/local-files/?d=`, `http` for an external static server, or `storage` when you use Label Studio's Storage sync), along with `LABEL_STUDIO_ROOT` and `LABEL_STUDIO_PREFIX` to match your server setup. Defaults: current working directory + `/data/local-files/?d=`.\n",
    "   - To mimic the LayoutLMv3 workflow, run `python serve_local_files.py --directory ../data/raw --port 8080` from the repo root, then set `LABEL_STUDIO_MODE=\"http\"`, `LABEL_STUDIO_ROOT` to the same folder, and `LABEL_STUDIO_PREFIX=\"http://localhost:8080/\"` before exporting.\n",
    "3. Run the conversion cell; it produces `output/ls_preannotations.json` containing Paddle predictions plus the correct file URLs.\n",
    "4. In your local Label Studio project choose **Import** â†’ upload `ls_preannotations.json`. The polygons appear as grey preannotations that you can refine instead of drawing manually."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "khmer-handwritten-recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
